2021-08-05 17:19:13.552017 (MainThread): Running with dbt=0.16.1
2021-08-05 17:19:13.624426 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/jdeng/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2021-08-05 17:19:13.625522 (MainThread): Tracking: tracking
2021-08-05 17:19:13.632038 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e47fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090ae390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090aec90>]}
2021-08-05 17:19:13.654312 (MainThread): Partial parsing not enabled
2021-08-05 17:19:13.657117 (MainThread): Parsing macros/core.sql
2021-08-05 17:19:13.662813 (MainThread): Parsing macros/materializations/helpers.sql
2021-08-05 17:19:13.671582 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2021-08-05 17:19:13.673639 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2021-08-05 17:19:13.692930 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2021-08-05 17:19:13.728397 (MainThread): Parsing macros/materializations/seed/seed.sql
2021-08-05 17:19:13.751585 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2021-08-05 17:19:13.753865 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2021-08-05 17:19:13.760773 (MainThread): Parsing macros/materializations/common/merge.sql
2021-08-05 17:19:13.774656 (MainThread): Parsing macros/materializations/table/table.sql
2021-08-05 17:19:13.782120 (MainThread): Parsing macros/materializations/view/view.sql
2021-08-05 17:19:13.789115 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2021-08-05 17:19:13.794732 (MainThread): Parsing macros/etc/get_custom_alias.sql
2021-08-05 17:19:13.795901 (MainThread): Parsing macros/etc/query.sql
2021-08-05 17:19:13.797210 (MainThread): Parsing macros/etc/is_incremental.sql
2021-08-05 17:19:13.799201 (MainThread): Parsing macros/etc/get_relation_comment.sql
2021-08-05 17:19:13.801609 (MainThread): Parsing macros/etc/datetime.sql
2021-08-05 17:19:13.811793 (MainThread): Parsing macros/etc/get_custom_schema.sql
2021-08-05 17:19:13.814175 (MainThread): Parsing macros/etc/get_custom_database.sql
2021-08-05 17:19:13.815733 (MainThread): Parsing macros/adapters/common.sql
2021-08-05 17:19:13.860052 (MainThread): Parsing macros/schema_tests/relationships.sql
2021-08-05 17:19:13.861718 (MainThread): Parsing macros/schema_tests/not_null.sql
2021-08-05 17:19:13.862927 (MainThread): Parsing macros/schema_tests/unique.sql
2021-08-05 17:19:13.864271 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2021-08-05 17:19:13.866923 (MainThread): Parsing macros/catalog.sql
2021-08-05 17:19:13.869719 (MainThread): Parsing macros/relations.sql
2021-08-05 17:19:13.871314 (MainThread): Parsing macros/adapters.sql
2021-08-05 17:19:13.889624 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2021-08-05 17:19:13.909039 (MainThread): Partial parsing not enabled
2021-08-05 17:19:13.939113 (MainThread): Acquiring new postgres connection "model.customer_history.dim_customers_email_acxiom".
2021-08-05 17:19:13.939245 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:13.956227 (MainThread): Acquiring new postgres connection "model.customer_history.fct_order_ticket_details".
2021-08-05 17:19:13.956350 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:13.965047 (MainThread): Acquiring new postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:13.965149 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:13.970009 (MainThread): Acquiring new postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:13.970117 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:13.974846 (MainThread): Acquiring new postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:13.974945 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:13.979541 (MainThread): Acquiring new postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:13.979638 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:13.983967 (MainThread): Acquiring new postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:13.984063 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:13.988652 (MainThread): Acquiring new postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:13.988759 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:13.993539 (MainThread): Acquiring new postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:13.993637 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:13.998530 (MainThread): Acquiring new postgres connection "model.customer_history.order_ticket_details_est".
2021-08-05 17:19:13.998629 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:14.005695 (MainThread): Acquiring new postgres connection "model.customer_history.order_flash_events_cst".
2021-08-05 17:19:14.005796 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:14.013342 (MainThread): Acquiring new postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:19:14.013450 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:14.020532 (MainThread): Acquiring new postgres connection "model.customer_history.order_flash_events_est".
2021-08-05 17:19:14.020640 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:14.028187 (MainThread): Acquiring new postgres connection "model.customer_history.order_ticket_details_mst".
2021-08-05 17:19:14.028290 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:14.035484 (MainThread): Acquiring new postgres connection "model.customer_history.order_flash_events_pst".
2021-08-05 17:19:14.035588 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:14.043442 (MainThread): Acquiring new postgres connection "model.customer_history.order_ticket_details_pst".
2021-08-05 17:19:14.043547 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:14.050579 (MainThread): Acquiring new postgres connection "model.customer_history.order_flash_events_mst".
2021-08-05 17:19:14.050694 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:14.232724 (MainThread): Found 17 models, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2021-08-05 17:19:14.239247 (MainThread): 
2021-08-05 17:19:14.239554 (MainThread): Acquiring new postgres connection "master".
2021-08-05 17:19:14.239643 (MainThread): Opening a new connection, currently in state init
2021-08-05 17:19:14.291375 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_data_platform_prod".
2021-08-05 17:19:14.291518 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2021-08-05 17:19:14.382109 (ThreadPoolExecutor-0_0): Using postgres connection "list_data_platform_prod".
2021-08-05 17:19:14.382233 (ThreadPoolExecutor-0_0): On list_data_platform_prod: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "connection_name": "list_data_platform_prod"} */

    select distinct nspname from pg_namespace
  
2021-08-05 17:19:15.009876 (ThreadPoolExecutor-0_0): SQL status: SELECT in 0.63 seconds
2021-08-05 17:19:15.064510 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_data_platform_prod_data_science".
2021-08-05 17:19:15.064697 (ThreadPoolExecutor-1_0): Re-using an available connection from the pool (formerly list_data_platform_prod).
2021-08-05 17:19:15.066101 (ThreadPoolExecutor-1_0): Using postgres connection "list_data_platform_prod_data_science".
2021-08-05 17:19:15.066210 (ThreadPoolExecutor-1_0): On list_data_platform_prod_data_science: BEGIN
2021-08-05 17:19:15.115232 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:19:15.115385 (ThreadPoolExecutor-1_0): Using postgres connection "list_data_platform_prod_data_science".
2021-08-05 17:19:15.115466 (ThreadPoolExecutor-1_0): On list_data_platform_prod_data_science: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "connection_name": "list_data_platform_prod_data_science"} */
select
      'data_platform_prod' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'data_science'
    union all
    select
      'data_platform_prod' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'data_science'
  
2021-08-05 17:19:15.193951 (ThreadPoolExecutor-1_0): SQL status: SELECT in 0.08 seconds
2021-08-05 17:19:15.220547 (ThreadPoolExecutor-1_0): On list_data_platform_prod_data_science: ROLLBACK
2021-08-05 17:19:15.337025 (MainThread): Using postgres connection "master".
2021-08-05 17:19:15.337156 (MainThread): On master: BEGIN
2021-08-05 17:19:15.870684 (MainThread): SQL status: BEGIN in 0.53 seconds
2021-08-05 17:19:15.870951 (MainThread): Using postgres connection "master".
2021-08-05 17:19:15.871050 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2021-08-05 17:19:16.026927 (MainThread): SQL status: SELECT in 0.16 seconds
2021-08-05 17:19:16.267300 (MainThread): On master: ROLLBACK
2021-08-05 17:19:16.316600 (MainThread): Using postgres connection "master".
2021-08-05 17:19:16.316761 (MainThread): On master: BEGIN
2021-08-05 17:19:16.411495 (MainThread): SQL status: BEGIN in 0.09 seconds
2021-08-05 17:19:16.411664 (MainThread): On master: COMMIT
2021-08-05 17:19:16.411754 (MainThread): Using postgres connection "master".
2021-08-05 17:19:16.411831 (MainThread): On master: COMMIT
2021-08-05 17:19:16.464081 (MainThread): SQL status: COMMIT in 0.05 seconds
2021-08-05 17:19:16.464475 (MainThread): 10:19:16 | Concurrency: 1 threads (target='dev')
2021-08-05 17:19:16.464619 (MainThread): 10:19:16 | 
2021-08-05 17:19:16.466723 (Thread-1): Began running node model.customer_history.stg_events
2021-08-05 17:19:16.466920 (Thread-1): 10:19:16 | 1 of 17 START view model data_science.stg_events..................... [RUN]
2021-08-05 17:19:16.467228 (Thread-1): Acquiring new postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:16.467330 (Thread-1): Re-using an available connection from the pool (formerly list_data_platform_prod_data_science).
2021-08-05 17:19:16.467436 (Thread-1): Compiling model.customer_history.stg_events
2021-08-05 17:19:16.481252 (Thread-1): Writing injected SQL for node "model.customer_history.stg_events"
2021-08-05 17:19:16.481949 (Thread-1): finished collecting timing info
2021-08-05 17:19:16.519264 (Thread-1): Using postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:16.519404 (Thread-1): On model.customer_history.stg_events: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_events"} */
drop view if exists "data_platform_prod"."data_science"."stg_events__dbt_tmp" cascade
2021-08-05 17:19:16.612955 (Thread-1): SQL status: DROP VIEW in 0.09 seconds
2021-08-05 17:19:16.615299 (Thread-1): Using postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:16.615400 (Thread-1): On model.customer_history.stg_events: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_events"} */
drop view if exists "data_platform_prod"."data_science"."stg_events__dbt_backup" cascade
2021-08-05 17:19:16.664812 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2021-08-05 17:19:16.666842 (Thread-1): Writing runtime SQL for node "model.customer_history.stg_events"
2021-08-05 17:19:16.667428 (Thread-1): Using postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:16.667522 (Thread-1): On model.customer_history.stg_events: BEGIN
2021-08-05 17:19:16.712302 (Thread-1): SQL status: BEGIN in 0.04 seconds
2021-08-05 17:19:16.712459 (Thread-1): Using postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:16.712544 (Thread-1): On model.customer_history.stg_events: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_events"} */

  create view "data_platform_prod"."data_science"."stg_events__dbt_tmp" as (
    with events as (
    SELECT
        event_unique_id,
        onsale_date,
        event_datetime,
        venue_unique_id,
        major_category_name
    FROM
        ticketing.events
        INNER JOIN analytics.event_onsale USING (event_unique_id)
        LEFT JOIN analytics.mdl_major_category_event USING (event_unique_id)
    WHERE event_name NOT ilike 'test event%'
        AND event_name NOT ilike '%base event%'
        AND event_name NOT ilike '% test event%'
        AND event_name NOT ilike '%- RR Base%'
        AND (nvl(ticketing.events.is_exclude,false)) is false
),
venues as (
    SELECT
        venue_unique_id,
        left(venue_zip, 5) as venue_zip,
        venue_type
        from ticketing.venues LEFT JOIN data_science.venue_type
        USING (venue_unique_id)
),
final as (
    SELECT
        *
    FROM events INNER JOIN venues USING (venue_unique_id)
)
SELECT * FROM final
  );

2021-08-05 17:19:16.779916 (Thread-1): SQL status: CREATE VIEW in 0.07 seconds
2021-08-05 17:19:16.783359 (Thread-1): Using postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:16.783453 (Thread-1): On model.customer_history.stg_events: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_events"} */
alter table "data_platform_prod"."data_science"."stg_events" rename to "stg_events__dbt_backup"
2021-08-05 17:19:16.835554 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:16.837806 (Thread-1): Using postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:16.837898 (Thread-1): On model.customer_history.stg_events: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_events"} */
alter table "data_platform_prod"."data_science"."stg_events__dbt_tmp" rename to "stg_events"
2021-08-05 17:19:16.890034 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:16.890932 (Thread-1): On model.customer_history.stg_events: COMMIT
2021-08-05 17:19:16.891026 (Thread-1): Using postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:16.891100 (Thread-1): On model.customer_history.stg_events: COMMIT
2021-08-05 17:19:17.089295 (Thread-1): SQL status: COMMIT in 0.20 seconds
2021-08-05 17:19:17.091297 (Thread-1): Using postgres connection "model.customer_history.stg_events".
2021-08-05 17:19:17.091402 (Thread-1): On model.customer_history.stg_events: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_events"} */
drop view if exists "data_platform_prod"."data_science"."stg_events__dbt_backup" cascade
2021-08-05 17:19:17.323386 (Thread-1): SQL status: DROP VIEW in 0.23 seconds
2021-08-05 17:19:17.325737 (Thread-1): finished collecting timing info
2021-08-05 17:19:17.326611 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109278090>]}
2021-08-05 17:19:17.326994 (Thread-1): 10:19:17 | 1 of 17 OK created view model data_science.stg_events................ [CREATE VIEW in 0.86s]
2021-08-05 17:19:17.327110 (Thread-1): Finished running node model.customer_history.stg_events
2021-08-05 17:19:17.327224 (Thread-1): Began running node model.customer_history.stg_flash
2021-08-05 17:19:17.327424 (Thread-1): 10:19:17 | 2 of 17 START view model data_science.stg_flash...................... [RUN]
2021-08-05 17:19:17.327790 (Thread-1): Acquiring new postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:17.327868 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.stg_events).
2021-08-05 17:19:17.328027 (Thread-1): Compiling model.customer_history.stg_flash
2021-08-05 17:19:17.333027 (Thread-1): Writing injected SQL for node "model.customer_history.stg_flash"
2021-08-05 17:19:17.333483 (Thread-1): finished collecting timing info
2021-08-05 17:19:17.339785 (Thread-1): Using postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:17.339888 (Thread-1): On model.customer_history.stg_flash: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_flash"} */
drop view if exists "data_platform_prod"."data_science"."stg_flash__dbt_tmp" cascade
2021-08-05 17:19:17.533537 (Thread-1): SQL status: DROP VIEW in 0.19 seconds
2021-08-05 17:19:17.536799 (Thread-1): Using postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:17.536915 (Thread-1): On model.customer_history.stg_flash: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_flash"} */
drop view if exists "data_platform_prod"."data_science"."stg_flash__dbt_backup" cascade
2021-08-05 17:19:17.720880 (Thread-1): SQL status: DROP VIEW in 0.18 seconds
2021-08-05 17:19:17.722346 (Thread-1): Writing runtime SQL for node "model.customer_history.stg_flash"
2021-08-05 17:19:17.723046 (Thread-1): Using postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:17.723145 (Thread-1): On model.customer_history.stg_flash: BEGIN
2021-08-05 17:19:17.771025 (Thread-1): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:19:17.771192 (Thread-1): Using postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:17.771270 (Thread-1): On model.customer_history.stg_flash: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_flash"} */

  create view "data_platform_prod"."data_science"."stg_flash__dbt_tmp" as (
    SELECT
    ticket_state,
    ticket_id,
    transfer_action_id,
    fk_order_unique_id,
    fk_seat_unique_id
FROM
    flash.tickets LEFT JOIN flash.forwards USING (ticket_id)
  );

2021-08-05 17:19:17.850832 (Thread-1): SQL status: CREATE VIEW in 0.08 seconds
2021-08-05 17:19:17.854340 (Thread-1): Using postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:17.854436 (Thread-1): On model.customer_history.stg_flash: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_flash"} */
alter table "data_platform_prod"."data_science"."stg_flash" rename to "stg_flash__dbt_backup"
2021-08-05 17:19:17.902814 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:17.905166 (Thread-1): Using postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:17.905289 (Thread-1): On model.customer_history.stg_flash: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_flash"} */
alter table "data_platform_prod"."data_science"."stg_flash__dbt_tmp" rename to "stg_flash"
2021-08-05 17:19:17.950529 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:17.951426 (Thread-1): On model.customer_history.stg_flash: COMMIT
2021-08-05 17:19:17.951520 (Thread-1): Using postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:17.951593 (Thread-1): On model.customer_history.stg_flash: COMMIT
2021-08-05 17:19:18.159579 (Thread-1): SQL status: COMMIT in 0.21 seconds
2021-08-05 17:19:18.162188 (Thread-1): Using postgres connection "model.customer_history.stg_flash".
2021-08-05 17:19:18.162286 (Thread-1): On model.customer_history.stg_flash: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_flash"} */
drop view if exists "data_platform_prod"."data_science"."stg_flash__dbt_backup" cascade
2021-08-05 17:19:18.370550 (Thread-1): SQL status: DROP VIEW in 0.21 seconds
2021-08-05 17:19:18.372982 (Thread-1): finished collecting timing info
2021-08-05 17:19:18.373525 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109523510>]}
2021-08-05 17:19:18.373715 (Thread-1): 10:19:18 | 2 of 17 OK created view model data_science.stg_flash................. [CREATE VIEW in 1.05s]
2021-08-05 17:19:18.373825 (Thread-1): Finished running node model.customer_history.stg_flash
2021-08-05 17:19:18.373937 (Thread-1): Began running node model.customer_history.stg_customers
2021-08-05 17:19:18.374082 (Thread-1): 10:19:18 | 3 of 17 START view model data_science.stg_customers.................. [RUN]
2021-08-05 17:19:18.374532 (Thread-1): Acquiring new postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:18.374782 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.stg_flash).
2021-08-05 17:19:18.374884 (Thread-1): Compiling model.customer_history.stg_customers
2021-08-05 17:19:18.379511 (Thread-1): Writing injected SQL for node "model.customer_history.stg_customers"
2021-08-05 17:19:18.379949 (Thread-1): finished collecting timing info
2021-08-05 17:19:18.385912 (Thread-1): Using postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:18.386016 (Thread-1): On model.customer_history.stg_customers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_customers"} */
drop view if exists "data_platform_prod"."data_science"."stg_customers__dbt_tmp" cascade
2021-08-05 17:19:18.596170 (Thread-1): SQL status: DROP VIEW in 0.21 seconds
2021-08-05 17:19:18.599205 (Thread-1): Using postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:18.599323 (Thread-1): On model.customer_history.stg_customers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_customers"} */
drop view if exists "data_platform_prod"."data_science"."stg_customers__dbt_backup" cascade
2021-08-05 17:19:18.817952 (Thread-1): SQL status: DROP VIEW in 0.22 seconds
2021-08-05 17:19:18.819447 (Thread-1): Writing runtime SQL for node "model.customer_history.stg_customers"
2021-08-05 17:19:18.820124 (Thread-1): Using postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:18.820213 (Thread-1): On model.customer_history.stg_customers: BEGIN
2021-08-05 17:19:18.890005 (Thread-1): SQL status: BEGIN in 0.07 seconds
2021-08-05 17:19:18.890210 (Thread-1): Using postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:18.890291 (Thread-1): On model.customer_history.stg_customers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_customers"} */

  create view "data_platform_prod"."data_science"."stg_customers__dbt_tmp" as (
    SELECT 
    axs_customer_id as customer_unique_id,
    axs_email_hash,
    -- left(zip, 5) as zip -- eleminate situation as 01234-1234
    zip_code as zip
FROM analytics.demographics_all -- instead of ticketing.customers

--  no need to join SQL at this moment
--     CASE WHEN b.email is not null THEN 1 ELSE 0 END AS is_broker
-- FROM ticketing.customers c LEFT JOIN analytics.yield_manager_partners b 
-- on lower(c.email)=lower(b.email)
  );

2021-08-05 17:19:18.953187 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2021-08-05 17:19:18.956799 (Thread-1): Using postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:18.956905 (Thread-1): On model.customer_history.stg_customers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_customers"} */
alter table "data_platform_prod"."data_science"."stg_customers" rename to "stg_customers__dbt_backup"
2021-08-05 17:19:19.008679 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:19.011430 (Thread-1): Using postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:19.011551 (Thread-1): On model.customer_history.stg_customers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_customers"} */
alter table "data_platform_prod"."data_science"."stg_customers__dbt_tmp" rename to "stg_customers"
2021-08-05 17:19:19.059978 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:19.061127 (Thread-1): On model.customer_history.stg_customers: COMMIT
2021-08-05 17:19:19.061253 (Thread-1): Using postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:19.061353 (Thread-1): On model.customer_history.stg_customers: COMMIT
2021-08-05 17:19:19.706070 (Thread-1): SQL status: COMMIT in 0.64 seconds
2021-08-05 17:19:19.707859 (Thread-1): Using postgres connection "model.customer_history.stg_customers".
2021-08-05 17:19:19.707958 (Thread-1): On model.customer_history.stg_customers: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_customers"} */
drop view if exists "data_platform_prod"."data_science"."stg_customers__dbt_backup" cascade
2021-08-05 17:19:19.914726 (Thread-1): SQL status: DROP VIEW in 0.21 seconds
2021-08-05 17:19:19.917011 (Thread-1): finished collecting timing info
2021-08-05 17:19:19.917712 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090fc3d0>]}
2021-08-05 17:19:19.917908 (Thread-1): 10:19:19 | 3 of 17 OK created view model data_science.stg_customers............. [CREATE VIEW in 1.54s]
2021-08-05 17:19:19.918022 (Thread-1): Finished running node model.customer_history.stg_customers
2021-08-05 17:19:19.918137 (Thread-1): Began running node model.customer_history.stg_order_cst
2021-08-05 17:19:19.918253 (Thread-1): 10:19:19 | 4 of 17 START view model data_science.stg_order_cst.................. [RUN]
2021-08-05 17:19:19.918478 (Thread-1): Acquiring new postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:19.918560 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.stg_customers).
2021-08-05 17:19:19.918640 (Thread-1): Compiling model.customer_history.stg_order_cst
2021-08-05 17:19:19.923289 (Thread-1): Writing injected SQL for node "model.customer_history.stg_order_cst"
2021-08-05 17:19:19.923676 (Thread-1): finished collecting timing info
2021-08-05 17:19:19.931023 (Thread-1): Using postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:19.931153 (Thread-1): On model.customer_history.stg_order_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_cst"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_cst__dbt_tmp" cascade
2021-08-05 17:19:20.211353 (Thread-1): SQL status: DROP VIEW in 0.28 seconds
2021-08-05 17:19:20.213578 (Thread-1): Using postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:20.213676 (Thread-1): On model.customer_history.stg_order_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_cst"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_cst__dbt_backup" cascade
2021-08-05 17:19:20.427543 (Thread-1): SQL status: DROP VIEW in 0.21 seconds
2021-08-05 17:19:20.429104 (Thread-1): Writing runtime SQL for node "model.customer_history.stg_order_cst"
2021-08-05 17:19:20.429528 (Thread-1): Using postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:20.429616 (Thread-1): On model.customer_history.stg_order_cst: BEGIN
2021-08-05 17:19:20.476412 (Thread-1): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:19:20.476606 (Thread-1): Using postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:20.476686 (Thread-1): On model.customer_history.stg_order_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_cst"} */

  create view "data_platform_prod"."data_science"."stg_order_cst__dbt_tmp" as (
    select
    order_ticket_unique_id,
    order_unique_id,
    customer_unique_id,
    amount_gross,
    channel,
    sale_datetime,
    -- zone_unique_id,
    pricing_mode_id,
    -- price_code_type,
    CASE WHEN price_code_type ilike '%season%' THEN 1 ELSE 0 END AS is_season_ticket,
    seat_unique_id,
    ticketing.order_tickets.event_unique_id,
    is_canceled
from ticketing.order_tickets
INNER JOIN config.context_configuration config USING(context_id)
INNER JOIN ticketing.price_codes USING(price_code_unique_id)
INNER JOIN ticketing.zones USING (zone_unique_id)
WHERE 
config.timezone = 'CST' and lower(zone_type_description) in ('admissions', 'premium seating')
  );

2021-08-05 17:19:20.543591 (Thread-1): SQL status: CREATE VIEW in 0.07 seconds
2021-08-05 17:19:20.547896 (Thread-1): Using postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:20.548048 (Thread-1): On model.customer_history.stg_order_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_cst"} */
alter table "data_platform_prod"."data_science"."stg_order_cst" rename to "stg_order_cst__dbt_backup"
2021-08-05 17:19:20.598840 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:20.601533 (Thread-1): Using postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:20.601644 (Thread-1): On model.customer_history.stg_order_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_cst"} */
alter table "data_platform_prod"."data_science"."stg_order_cst__dbt_tmp" rename to "stg_order_cst"
2021-08-05 17:19:20.649745 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:20.650685 (Thread-1): On model.customer_history.stg_order_cst: COMMIT
2021-08-05 17:19:20.650777 (Thread-1): Using postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:20.650852 (Thread-1): On model.customer_history.stg_order_cst: COMMIT
2021-08-05 17:19:20.853721 (Thread-1): SQL status: COMMIT in 0.20 seconds
2021-08-05 17:19:20.855490 (Thread-1): Using postgres connection "model.customer_history.stg_order_cst".
2021-08-05 17:19:20.855583 (Thread-1): On model.customer_history.stg_order_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_cst"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_cst__dbt_backup" cascade
2021-08-05 17:19:21.079133 (Thread-1): SQL status: DROP VIEW in 0.22 seconds
2021-08-05 17:19:21.081340 (Thread-1): finished collecting timing info
2021-08-05 17:19:21.081878 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094d4450>]}
2021-08-05 17:19:21.082071 (Thread-1): 10:19:21 | 4 of 17 OK created view model data_science.stg_order_cst............. [CREATE VIEW in 1.16s]
2021-08-05 17:19:21.082182 (Thread-1): Finished running node model.customer_history.stg_order_cst
2021-08-05 17:19:21.082295 (Thread-1): Began running node model.customer_history.stg_order_est
2021-08-05 17:19:21.082453 (Thread-1): 10:19:21 | 5 of 17 START view model data_science.stg_order_est.................. [RUN]
2021-08-05 17:19:21.082915 (Thread-1): Acquiring new postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:21.083416 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.stg_order_cst).
2021-08-05 17:19:21.083512 (Thread-1): Compiling model.customer_history.stg_order_est
2021-08-05 17:19:21.088184 (Thread-1): Writing injected SQL for node "model.customer_history.stg_order_est"
2021-08-05 17:19:21.088588 (Thread-1): finished collecting timing info
2021-08-05 17:19:21.094904 (Thread-1): Using postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:21.095018 (Thread-1): On model.customer_history.stg_order_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_est"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_est__dbt_tmp" cascade
2021-08-05 17:19:21.297750 (Thread-1): SQL status: DROP VIEW in 0.20 seconds
2021-08-05 17:19:21.300008 (Thread-1): Using postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:21.300101 (Thread-1): On model.customer_history.stg_order_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_est"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_est__dbt_backup" cascade
2021-08-05 17:19:21.462022 (Thread-1): SQL status: DROP VIEW in 0.16 seconds
2021-08-05 17:19:21.463514 (Thread-1): Writing runtime SQL for node "model.customer_history.stg_order_est"
2021-08-05 17:19:21.464043 (Thread-1): Using postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:21.464140 (Thread-1): On model.customer_history.stg_order_est: BEGIN
2021-08-05 17:19:21.523632 (Thread-1): SQL status: BEGIN in 0.06 seconds
2021-08-05 17:19:21.523783 (Thread-1): Using postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:21.523864 (Thread-1): On model.customer_history.stg_order_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_est"} */

  create view "data_platform_prod"."data_science"."stg_order_est__dbt_tmp" as (
    select
    order_ticket_unique_id,
    order_unique_id,
    customer_unique_id,
    amount_gross,
    channel,
    sale_datetime,
    -- zone_unique_id,
    pricing_mode_id,
    -- price_code_type,
    CASE WHEN price_code_type ilike '%season%' THEN 1 ELSE 0 END AS is_season_ticket,
    seat_unique_id,
    ticketing.order_tickets.event_unique_id,
    is_canceled
from ticketing.order_tickets
INNER JOIN config.context_configuration config USING(context_id)
INNER JOIN ticketing.price_codes USING(price_code_unique_id)
INNER JOIN ticketing.zones USING (zone_unique_id)
WHERE 
config.timezone = 'EST' and lower(zone_type_description) in ('admissions', 'premium seating')
  );

2021-08-05 17:19:21.612034 (Thread-1): SQL status: CREATE VIEW in 0.09 seconds
2021-08-05 17:19:21.615764 (Thread-1): Using postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:21.615876 (Thread-1): On model.customer_history.stg_order_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_est"} */
alter table "data_platform_prod"."data_science"."stg_order_est" rename to "stg_order_est__dbt_backup"
2021-08-05 17:19:21.702453 (Thread-1): SQL status: ALTER TABLE in 0.09 seconds
2021-08-05 17:19:21.705533 (Thread-1): Using postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:21.705632 (Thread-1): On model.customer_history.stg_order_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_est"} */
alter table "data_platform_prod"."data_science"."stg_order_est__dbt_tmp" rename to "stg_order_est"
2021-08-05 17:19:21.816176 (Thread-1): SQL status: ALTER TABLE in 0.11 seconds
2021-08-05 17:19:21.817209 (Thread-1): On model.customer_history.stg_order_est: COMMIT
2021-08-05 17:19:21.817320 (Thread-1): Using postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:21.817408 (Thread-1): On model.customer_history.stg_order_est: COMMIT
2021-08-05 17:19:22.053456 (Thread-1): SQL status: COMMIT in 0.24 seconds
2021-08-05 17:19:22.055221 (Thread-1): Using postgres connection "model.customer_history.stg_order_est".
2021-08-05 17:19:22.055311 (Thread-1): On model.customer_history.stg_order_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_est"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_est__dbt_backup" cascade
2021-08-05 17:19:22.361515 (Thread-1): SQL status: DROP VIEW in 0.31 seconds
2021-08-05 17:19:22.364355 (Thread-1): finished collecting timing info
2021-08-05 17:19:22.365073 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109312f10>]}
2021-08-05 17:19:22.365323 (Thread-1): 10:19:22 | 5 of 17 OK created view model data_science.stg_order_est............. [CREATE VIEW in 1.28s]
2021-08-05 17:19:22.365469 (Thread-1): Finished running node model.customer_history.stg_order_est
2021-08-05 17:19:22.365616 (Thread-1): Began running node model.customer_history.stg_order_mst
2021-08-05 17:19:22.365770 (Thread-1): 10:19:22 | 6 of 17 START view model data_science.stg_order_mst.................. [RUN]
2021-08-05 17:19:22.366309 (Thread-1): Acquiring new postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:22.366577 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.stg_order_est).
2021-08-05 17:19:22.366875 (Thread-1): Compiling model.customer_history.stg_order_mst
2021-08-05 17:19:22.373242 (Thread-1): Writing injected SQL for node "model.customer_history.stg_order_mst"
2021-08-05 17:19:22.373700 (Thread-1): finished collecting timing info
2021-08-05 17:19:22.381854 (Thread-1): Using postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:22.381988 (Thread-1): On model.customer_history.stg_order_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_mst"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_mst__dbt_tmp" cascade
2021-08-05 17:19:22.649158 (Thread-1): SQL status: DROP VIEW in 0.27 seconds
2021-08-05 17:19:22.652031 (Thread-1): Using postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:22.652158 (Thread-1): On model.customer_history.stg_order_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_mst"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_mst__dbt_backup" cascade
2021-08-05 17:19:23.829785 (Thread-1): SQL status: DROP VIEW in 1.18 seconds
2021-08-05 17:19:23.831367 (Thread-1): Writing runtime SQL for node "model.customer_history.stg_order_mst"
2021-08-05 17:19:23.831858 (Thread-1): Using postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:23.831953 (Thread-1): On model.customer_history.stg_order_mst: BEGIN
2021-08-05 17:19:23.927093 (Thread-1): SQL status: BEGIN in 0.10 seconds
2021-08-05 17:19:23.927257 (Thread-1): Using postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:23.927340 (Thread-1): On model.customer_history.stg_order_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_mst"} */

  create view "data_platform_prod"."data_science"."stg_order_mst__dbt_tmp" as (
    select
    order_ticket_unique_id,
    order_unique_id,
    customer_unique_id,
    amount_gross,
    channel,
    sale_datetime,
    -- zone_unique_id,
    pricing_mode_id,
    -- price_code_type,
    CASE WHEN price_code_type ilike '%season%' THEN 1 ELSE 0 END AS is_season_ticket,
    seat_unique_id,
    ticketing.order_tickets.event_unique_id,
    is_canceled
from ticketing.order_tickets
INNER JOIN config.context_configuration config USING(context_id)
INNER JOIN ticketing.price_codes USING(price_code_unique_id)
INNER JOIN ticketing.zones USING (zone_unique_id)
WHERE 
config.timezone = 'MST' and lower(zone_type_description) in ('admissions', 'premium seating')
  );

2021-08-05 17:19:24.287693 (Thread-1): SQL status: CREATE VIEW in 0.36 seconds
2021-08-05 17:19:24.291786 (Thread-1): Using postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:24.291907 (Thread-1): On model.customer_history.stg_order_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_mst"} */
alter table "data_platform_prod"."data_science"."stg_order_mst" rename to "stg_order_mst__dbt_backup"
2021-08-05 17:19:24.376452 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2021-08-05 17:19:24.379047 (Thread-1): Using postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:24.379169 (Thread-1): On model.customer_history.stg_order_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_mst"} */
alter table "data_platform_prod"."data_science"."stg_order_mst__dbt_tmp" rename to "stg_order_mst"
2021-08-05 17:19:24.438162 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2021-08-05 17:19:24.439201 (Thread-1): On model.customer_history.stg_order_mst: COMMIT
2021-08-05 17:19:24.439330 (Thread-1): Using postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:24.439421 (Thread-1): On model.customer_history.stg_order_mst: COMMIT
2021-08-05 17:19:24.645105 (Thread-1): SQL status: COMMIT in 0.21 seconds
2021-08-05 17:19:24.647008 (Thread-1): Using postgres connection "model.customer_history.stg_order_mst".
2021-08-05 17:19:24.647114 (Thread-1): On model.customer_history.stg_order_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_mst"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_mst__dbt_backup" cascade
2021-08-05 17:19:24.859592 (Thread-1): SQL status: DROP VIEW in 0.21 seconds
2021-08-05 17:19:24.861817 (Thread-1): finished collecting timing info
2021-08-05 17:19:24.862368 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109312f10>]}
2021-08-05 17:19:24.862565 (Thread-1): 10:19:24 | 6 of 17 OK created view model data_science.stg_order_mst............. [CREATE VIEW in 2.50s]
2021-08-05 17:19:24.862680 (Thread-1): Finished running node model.customer_history.stg_order_mst
2021-08-05 17:19:24.862806 (Thread-1): Began running node model.customer_history.stg_order_pst
2021-08-05 17:19:24.862942 (Thread-1): 10:19:24 | 7 of 17 START view model data_science.stg_order_pst.................. [RUN]
2021-08-05 17:19:24.863296 (Thread-1): Acquiring new postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:24.863475 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.stg_order_mst).
2021-08-05 17:19:24.863583 (Thread-1): Compiling model.customer_history.stg_order_pst
2021-08-05 17:19:24.868720 (Thread-1): Writing injected SQL for node "model.customer_history.stg_order_pst"
2021-08-05 17:19:24.869215 (Thread-1): finished collecting timing info
2021-08-05 17:19:24.876338 (Thread-1): Using postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:24.876459 (Thread-1): On model.customer_history.stg_order_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_pst"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_pst__dbt_tmp" cascade
2021-08-05 17:19:25.094435 (Thread-1): SQL status: DROP VIEW in 0.22 seconds
2021-08-05 17:19:25.096672 (Thread-1): Using postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:25.096831 (Thread-1): On model.customer_history.stg_order_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_pst"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_pst__dbt_backup" cascade
2021-08-05 17:19:25.313549 (Thread-1): SQL status: DROP VIEW in 0.22 seconds
2021-08-05 17:19:25.315107 (Thread-1): Writing runtime SQL for node "model.customer_history.stg_order_pst"
2021-08-05 17:19:25.315614 (Thread-1): Using postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:25.315703 (Thread-1): On model.customer_history.stg_order_pst: BEGIN
2021-08-05 17:19:25.361570 (Thread-1): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:19:25.361733 (Thread-1): Using postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:25.361819 (Thread-1): On model.customer_history.stg_order_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_pst"} */

  create view "data_platform_prod"."data_science"."stg_order_pst__dbt_tmp" as (
    select
    order_ticket_unique_id,
    order_unique_id,
    customer_unique_id,
    amount_gross,
    channel,
    sale_datetime,
    -- zone_unique_id,
    pricing_mode_id,
    -- price_code_type,
    CASE WHEN price_code_type ilike '%season%' THEN 1 ELSE 0 END AS is_season_ticket,
    seat_unique_id,
    ticketing.order_tickets.event_unique_id,
    is_canceled
from ticketing.order_tickets
INNER JOIN config.context_configuration config USING(context_id)
INNER JOIN ticketing.price_codes USING(price_code_unique_id)
INNER JOIN ticketing.zones USING (zone_unique_id)
WHERE 
config.timezone = 'PST' and lower(zone_type_description) in ('admissions', 'premium seating')
  );

2021-08-05 17:19:25.426875 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2021-08-05 17:19:25.430329 (Thread-1): Using postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:25.430455 (Thread-1): On model.customer_history.stg_order_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_pst"} */
alter table "data_platform_prod"."data_science"."stg_order_pst" rename to "stg_order_pst__dbt_backup"
2021-08-05 17:19:25.480566 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:25.482866 (Thread-1): Using postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:25.482958 (Thread-1): On model.customer_history.stg_order_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_pst"} */
alter table "data_platform_prod"."data_science"."stg_order_pst__dbt_tmp" rename to "stg_order_pst"
2021-08-05 17:19:25.531978 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:25.532964 (Thread-1): On model.customer_history.stg_order_pst: COMMIT
2021-08-05 17:19:25.533058 (Thread-1): Using postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:25.533132 (Thread-1): On model.customer_history.stg_order_pst: COMMIT
2021-08-05 17:19:25.735328 (Thread-1): SQL status: COMMIT in 0.20 seconds
2021-08-05 17:19:25.737350 (Thread-1): Using postgres connection "model.customer_history.stg_order_pst".
2021-08-05 17:19:25.737492 (Thread-1): On model.customer_history.stg_order_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.stg_order_pst"} */
drop view if exists "data_platform_prod"."data_science"."stg_order_pst__dbt_backup" cascade
2021-08-05 17:19:25.937019 (Thread-1): SQL status: DROP VIEW in 0.20 seconds
2021-08-05 17:19:25.939193 (Thread-1): finished collecting timing info
2021-08-05 17:19:25.939727 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094ed290>]}
2021-08-05 17:19:25.939917 (Thread-1): 10:19:25 | 7 of 17 OK created view model data_science.stg_order_pst............. [CREATE VIEW in 1.08s]
2021-08-05 17:19:25.940026 (Thread-1): Finished running node model.customer_history.stg_order_pst
2021-08-05 17:19:25.940137 (Thread-1): Began running node model.customer_history.order_flash_events_cst
2021-08-05 17:19:25.940310 (Thread-1): 10:19:25 | 8 of 17 START view model data_science.order_flash_events_cst......... [RUN]
2021-08-05 17:19:25.940795 (Thread-1): Acquiring new postgres connection "model.customer_history.order_flash_events_cst".
2021-08-05 17:19:25.941051 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.stg_order_pst).
2021-08-05 17:19:25.941149 (Thread-1): Compiling model.customer_history.order_flash_events_cst
2021-08-05 17:19:25.949666 (Thread-1): Writing injected SQL for node "model.customer_history.order_flash_events_cst"
2021-08-05 17:19:25.950156 (Thread-1): finished collecting timing info
2021-08-05 17:19:25.956381 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_cst".
2021-08-05 17:19:25.956488 (Thread-1): On model.customer_history.order_flash_events_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_cst"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_cst__dbt_tmp" cascade
2021-08-05 17:19:26.207238 (Thread-1): SQL status: DROP VIEW in 0.25 seconds
2021-08-05 17:19:26.209531 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_cst".
2021-08-05 17:19:26.209633 (Thread-1): On model.customer_history.order_flash_events_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_cst"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_cst__dbt_backup" cascade
2021-08-05 17:19:26.449406 (Thread-1): SQL status: DROP VIEW in 0.24 seconds
2021-08-05 17:19:26.450893 (Thread-1): Writing runtime SQL for node "model.customer_history.order_flash_events_cst"
2021-08-05 17:19:26.451476 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_cst".
2021-08-05 17:19:26.451574 (Thread-1): On model.customer_history.order_flash_events_cst: BEGIN
2021-08-05 17:19:26.503897 (Thread-1): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:19:26.504045 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_cst".
2021-08-05 17:19:26.504124 (Thread-1): On model.customer_history.order_flash_events_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_cst"} */

  create view "data_platform_prod"."data_science"."order_flash_events_cst__dbt_tmp" as (
    with orders as (
    select * from "data_platform_prod"."data_science"."stg_order_cst"
),
events as (
    select * from "data_platform_prod"."data_science"."stg_events"
),
flash as (
    select * from "data_platform_prod"."data_science"."stg_flash"
),
order_flash as (
    SELECT *
    from orders LEFT JOIN flash ON flash.fk_order_unique_id=orders.order_unique_id
        and flash.fk_seat_unique_id=orders.seat_unique_id
),

final as (
    SELECT
    order_ticket_unique_id,
    order_unique_id,
    customer_unique_id,
    amount_gross,
    channel,
    sale_datetime,
    pricing_mode_id,
    is_season_ticket,
    transfer_action_id,
    events.event_unique_id,
    ticket_id,
    ticket_state,
    venue_unique_id,
    venue_zip,
    venue_type,
    datediff(days, onsale_date, sale_datetime) AS days_sold_after_onsale,
    datediff(days, sale_datetime, event_datetime) AS days_sold_before_event,
    major_category_name,
    is_canceled
    FROM order_flash INNER JOIN events USING (event_unique_id)
)

SELECT * FROM final
  );

2021-08-05 17:19:26.598353 (Thread-1): SQL status: CREATE VIEW in 0.09 seconds
2021-08-05 17:19:26.600988 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_cst".
2021-08-05 17:19:26.601143 (Thread-1): On model.customer_history.order_flash_events_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_cst"} */
alter table "data_platform_prod"."data_science"."order_flash_events_cst__dbt_tmp" rename to "order_flash_events_cst"
2021-08-05 17:19:26.652625 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:26.653527 (Thread-1): On model.customer_history.order_flash_events_cst: COMMIT
2021-08-05 17:19:26.653623 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_cst".
2021-08-05 17:19:26.653698 (Thread-1): On model.customer_history.order_flash_events_cst: COMMIT
2021-08-05 17:19:26.820934 (Thread-1): SQL status: COMMIT in 0.17 seconds
2021-08-05 17:19:26.823679 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_cst".
2021-08-05 17:19:26.823777 (Thread-1): On model.customer_history.order_flash_events_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_cst"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_cst__dbt_backup" cascade
2021-08-05 17:19:27.030491 (Thread-1): SQL status: DROP VIEW in 0.21 seconds
2021-08-05 17:19:27.032938 (Thread-1): finished collecting timing info
2021-08-05 17:19:27.033514 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10932a5d0>]}
2021-08-05 17:19:27.033711 (Thread-1): 10:19:27 | 8 of 17 OK created view model data_science.order_flash_events_cst.... [CREATE VIEW in 1.09s]
2021-08-05 17:19:27.033825 (Thread-1): Finished running node model.customer_history.order_flash_events_cst
2021-08-05 17:19:27.033941 (Thread-1): Began running node model.customer_history.order_flash_events_est
2021-08-05 17:19:27.034061 (Thread-1): 10:19:27 | 9 of 17 START view model data_science.order_flash_events_est......... [RUN]
2021-08-05 17:19:27.034515 (Thread-1): Acquiring new postgres connection "model.customer_history.order_flash_events_est".
2021-08-05 17:19:27.034749 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.order_flash_events_cst).
2021-08-05 17:19:27.034859 (Thread-1): Compiling model.customer_history.order_flash_events_est
2021-08-05 17:19:27.044166 (Thread-1): Writing injected SQL for node "model.customer_history.order_flash_events_est"
2021-08-05 17:19:27.044595 (Thread-1): finished collecting timing info
2021-08-05 17:19:27.051859 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_est".
2021-08-05 17:19:27.052039 (Thread-1): On model.customer_history.order_flash_events_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_est"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_est__dbt_tmp" cascade
2021-08-05 17:19:27.270123 (Thread-1): SQL status: DROP VIEW in 0.22 seconds
2021-08-05 17:19:27.272790 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_est".
2021-08-05 17:19:27.272897 (Thread-1): On model.customer_history.order_flash_events_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_est"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_est__dbt_backup" cascade
2021-08-05 17:19:27.501509 (Thread-1): SQL status: DROP VIEW in 0.23 seconds
2021-08-05 17:19:27.503061 (Thread-1): Writing runtime SQL for node "model.customer_history.order_flash_events_est"
2021-08-05 17:19:27.503587 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_est".
2021-08-05 17:19:27.503688 (Thread-1): On model.customer_history.order_flash_events_est: BEGIN
2021-08-05 17:19:27.548941 (Thread-1): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:19:27.549119 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_est".
2021-08-05 17:19:27.549200 (Thread-1): On model.customer_history.order_flash_events_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_est"} */

  create view "data_platform_prod"."data_science"."order_flash_events_est__dbt_tmp" as (
    with orders as (
    select * from "data_platform_prod"."data_science"."stg_order_est"
),
events as (
    select * from "data_platform_prod"."data_science"."stg_events"
),
flash as (
    select * from "data_platform_prod"."data_science"."stg_flash"
),
order_flash as (
    SELECT *
    from orders LEFT JOIN flash ON flash.fk_order_unique_id=orders.order_unique_id
        and flash.fk_seat_unique_id=orders.seat_unique_id
),

final as (
    SELECT
    order_ticket_unique_id,
    order_unique_id,
    customer_unique_id,
    amount_gross,
    channel,
    sale_datetime,
    pricing_mode_id,
    is_season_ticket,
    transfer_action_id,
    events.event_unique_id,
    ticket_id,
    ticket_state,
    venue_unique_id,
    venue_zip,
    venue_type,
    datediff(days, onsale_date, sale_datetime) AS days_sold_after_onsale,
    datediff(days, sale_datetime, event_datetime) AS days_sold_before_event,
    major_category_name,
    is_canceled
    FROM order_flash INNER JOIN events USING (event_unique_id)
)

SELECT * FROM final
  );

2021-08-05 17:19:27.632253 (Thread-1): SQL status: CREATE VIEW in 0.08 seconds
2021-08-05 17:19:27.634522 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_est".
2021-08-05 17:19:27.634616 (Thread-1): On model.customer_history.order_flash_events_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_est"} */
alter table "data_platform_prod"."data_science"."order_flash_events_est__dbt_tmp" rename to "order_flash_events_est"
2021-08-05 17:19:27.682319 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:27.683225 (Thread-1): On model.customer_history.order_flash_events_est: COMMIT
2021-08-05 17:19:27.683322 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_est".
2021-08-05 17:19:27.683398 (Thread-1): On model.customer_history.order_flash_events_est: COMMIT
2021-08-05 17:19:27.888717 (Thread-1): SQL status: COMMIT in 0.21 seconds
2021-08-05 17:19:27.890658 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_est".
2021-08-05 17:19:27.890769 (Thread-1): On model.customer_history.order_flash_events_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_est"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_est__dbt_backup" cascade
2021-08-05 17:19:28.090237 (Thread-1): SQL status: DROP VIEW in 0.20 seconds
2021-08-05 17:19:28.092485 (Thread-1): finished collecting timing info
2021-08-05 17:19:28.093039 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109540110>]}
2021-08-05 17:19:28.093232 (Thread-1): 10:19:28 | 9 of 17 OK created view model data_science.order_flash_events_est.... [CREATE VIEW in 1.06s]
2021-08-05 17:19:28.093345 (Thread-1): Finished running node model.customer_history.order_flash_events_est
2021-08-05 17:19:28.093459 (Thread-1): Began running node model.customer_history.order_flash_events_mst
2021-08-05 17:19:28.093646 (Thread-1): 10:19:28 | 10 of 17 START view model data_science.order_flash_events_mst........ [RUN]
2021-08-05 17:19:28.094128 (Thread-1): Acquiring new postgres connection "model.customer_history.order_flash_events_mst".
2021-08-05 17:19:28.094263 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.order_flash_events_est).
2021-08-05 17:19:28.094391 (Thread-1): Compiling model.customer_history.order_flash_events_mst
2021-08-05 17:19:28.102445 (Thread-1): Writing injected SQL for node "model.customer_history.order_flash_events_mst"
2021-08-05 17:19:28.102891 (Thread-1): finished collecting timing info
2021-08-05 17:19:28.108832 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_mst".
2021-08-05 17:19:28.109035 (Thread-1): On model.customer_history.order_flash_events_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_mst"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_mst__dbt_tmp" cascade
2021-08-05 17:19:28.812690 (Thread-1): SQL status: DROP VIEW in 0.70 seconds
2021-08-05 17:19:28.815204 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_mst".
2021-08-05 17:19:28.815318 (Thread-1): On model.customer_history.order_flash_events_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_mst"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_mst__dbt_backup" cascade
2021-08-05 17:19:29.389702 (Thread-1): SQL status: DROP VIEW in 0.57 seconds
2021-08-05 17:19:29.392208 (Thread-1): Writing runtime SQL for node "model.customer_history.order_flash_events_mst"
2021-08-05 17:19:29.392618 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_mst".
2021-08-05 17:19:29.392707 (Thread-1): On model.customer_history.order_flash_events_mst: BEGIN
2021-08-05 17:19:29.443106 (Thread-1): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:19:29.443331 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_mst".
2021-08-05 17:19:29.443412 (Thread-1): On model.customer_history.order_flash_events_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_mst"} */

  create view "data_platform_prod"."data_science"."order_flash_events_mst__dbt_tmp" as (
    with orders as (
    select * from "data_platform_prod"."data_science"."stg_order_mst"
),
events as (
    select * from "data_platform_prod"."data_science"."stg_events"
),
flash as (
    select * from "data_platform_prod"."data_science"."stg_flash"
),
order_flash as (
    SELECT *
    from orders LEFT JOIN flash ON flash.fk_order_unique_id=orders.order_unique_id
        and flash.fk_seat_unique_id=orders.seat_unique_id
),

final as (
    SELECT
    order_ticket_unique_id,
    order_unique_id,
    customer_unique_id,
    amount_gross,
    channel,
    sale_datetime,
    pricing_mode_id,
    is_season_ticket,
    transfer_action_id,
    events.event_unique_id,
    ticket_id,
    ticket_state,
    venue_unique_id,
    venue_zip,
    venue_type,
    datediff(days, onsale_date, sale_datetime) AS days_sold_after_onsale,
    datediff(days, sale_datetime, event_datetime) AS days_sold_before_event,
    major_category_name,
    is_canceled
    FROM order_flash INNER JOIN events USING (event_unique_id)
)

SELECT * FROM final
  );

2021-08-05 17:19:29.517334 (Thread-1): SQL status: CREATE VIEW in 0.07 seconds
2021-08-05 17:19:29.519564 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_mst".
2021-08-05 17:19:29.519661 (Thread-1): On model.customer_history.order_flash_events_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_mst"} */
alter table "data_platform_prod"."data_science"."order_flash_events_mst__dbt_tmp" rename to "order_flash_events_mst"
2021-08-05 17:19:29.573961 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:29.574908 (Thread-1): On model.customer_history.order_flash_events_mst: COMMIT
2021-08-05 17:19:29.575003 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_mst".
2021-08-05 17:19:29.575077 (Thread-1): On model.customer_history.order_flash_events_mst: COMMIT
2021-08-05 17:19:29.806755 (Thread-1): SQL status: COMMIT in 0.23 seconds
2021-08-05 17:19:29.808513 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_mst".
2021-08-05 17:19:29.808604 (Thread-1): On model.customer_history.order_flash_events_mst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_mst"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_mst__dbt_backup" cascade
2021-08-05 17:19:30.150468 (Thread-1): SQL status: DROP VIEW in 0.34 seconds
2021-08-05 17:19:30.153055 (Thread-1): finished collecting timing info
2021-08-05 17:19:30.153702 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109278090>]}
2021-08-05 17:19:30.153931 (Thread-1): 10:19:30 | 10 of 17 OK created view model data_science.order_flash_events_mst... [CREATE VIEW in 2.06s]
2021-08-05 17:19:30.154062 (Thread-1): Finished running node model.customer_history.order_flash_events_mst
2021-08-05 17:19:30.154197 (Thread-1): Began running node model.customer_history.order_flash_events_pst
2021-08-05 17:19:30.154583 (Thread-1): 10:19:30 | 11 of 17 START view model data_science.order_flash_events_pst........ [RUN]
2021-08-05 17:19:30.154953 (Thread-1): Acquiring new postgres connection "model.customer_history.order_flash_events_pst".
2021-08-05 17:19:30.155059 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.order_flash_events_mst).
2021-08-05 17:19:30.155154 (Thread-1): Compiling model.customer_history.order_flash_events_pst
2021-08-05 17:19:30.164248 (Thread-1): Writing injected SQL for node "model.customer_history.order_flash_events_pst"
2021-08-05 17:19:30.164633 (Thread-1): finished collecting timing info
2021-08-05 17:19:30.171870 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_pst".
2021-08-05 17:19:30.171996 (Thread-1): On model.customer_history.order_flash_events_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_pst"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_pst__dbt_tmp" cascade
2021-08-05 17:19:31.047454 (Thread-1): SQL status: DROP VIEW in 0.88 seconds
2021-08-05 17:19:31.049655 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_pst".
2021-08-05 17:19:31.049751 (Thread-1): On model.customer_history.order_flash_events_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_pst"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_pst__dbt_backup" cascade
2021-08-05 17:19:31.291309 (Thread-1): SQL status: DROP VIEW in 0.24 seconds
2021-08-05 17:19:31.292805 (Thread-1): Writing runtime SQL for node "model.customer_history.order_flash_events_pst"
2021-08-05 17:19:31.293299 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_pst".
2021-08-05 17:19:31.293417 (Thread-1): On model.customer_history.order_flash_events_pst: BEGIN
2021-08-05 17:19:31.342348 (Thread-1): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:19:31.342499 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_pst".
2021-08-05 17:19:31.342579 (Thread-1): On model.customer_history.order_flash_events_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_pst"} */

  create view "data_platform_prod"."data_science"."order_flash_events_pst__dbt_tmp" as (
    with orders as (
    select * from "data_platform_prod"."data_science"."stg_order_pst"
),
events as (
    select * from "data_platform_prod"."data_science"."stg_events"
),
flash as (
    select * from "data_platform_prod"."data_science"."stg_flash"
),
order_flash as (
    SELECT *
    from orders LEFT JOIN flash ON flash.fk_order_unique_id=orders.order_unique_id
        and flash.fk_seat_unique_id=orders.seat_unique_id
),

final as (
    SELECT
    order_ticket_unique_id,
    order_unique_id,
    customer_unique_id,
    amount_gross,
    channel,
    sale_datetime,
    pricing_mode_id,
    is_season_ticket,
    transfer_action_id,
    events.event_unique_id,
    ticket_id,
    ticket_state,
    venue_unique_id,
    venue_zip,
    venue_type,
    datediff(days, onsale_date, sale_datetime) AS days_sold_after_onsale,
    datediff(days, sale_datetime, event_datetime) AS days_sold_before_event,
    major_category_name,
    is_canceled
    FROM order_flash INNER JOIN events USING (event_unique_id)
)

SELECT * FROM final
  );

2021-08-05 17:19:31.405131 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2021-08-05 17:19:31.407437 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_pst".
2021-08-05 17:19:31.407535 (Thread-1): On model.customer_history.order_flash_events_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_pst"} */
alter table "data_platform_prod"."data_science"."order_flash_events_pst__dbt_tmp" rename to "order_flash_events_pst"
2021-08-05 17:19:31.454155 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:19:31.455096 (Thread-1): On model.customer_history.order_flash_events_pst: COMMIT
2021-08-05 17:19:31.455186 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_pst".
2021-08-05 17:19:31.455260 (Thread-1): On model.customer_history.order_flash_events_pst: COMMIT
2021-08-05 17:19:31.808015 (Thread-1): SQL status: COMMIT in 0.35 seconds
2021-08-05 17:19:31.809877 (Thread-1): Using postgres connection "model.customer_history.order_flash_events_pst".
2021-08-05 17:19:31.809984 (Thread-1): On model.customer_history.order_flash_events_pst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_flash_events_pst"} */
drop view if exists "data_platform_prod"."data_science"."order_flash_events_pst__dbt_backup" cascade
2021-08-05 17:19:32.011619 (Thread-1): SQL status: DROP VIEW in 0.20 seconds
2021-08-05 17:19:32.014199 (Thread-1): finished collecting timing info
2021-08-05 17:19:32.014837 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10932ab50>]}
2021-08-05 17:19:32.015063 (Thread-1): 10:19:32 | 11 of 17 OK created view model data_science.order_flash_events_pst... [CREATE VIEW in 1.86s]
2021-08-05 17:19:32.015194 (Thread-1): Finished running node model.customer_history.order_flash_events_pst
2021-08-05 17:19:32.015326 (Thread-1): Began running node model.customer_history.order_ticket_details_cst
2021-08-05 17:19:32.015514 (Thread-1): 10:19:32 | 12 of 17 START table model data_science.order_ticket_details_cst..... [RUN]
2021-08-05 17:19:32.015812 (Thread-1): Acquiring new postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:19:32.015911 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.order_flash_events_pst).
2021-08-05 17:19:32.016208 (Thread-1): Compiling model.customer_history.order_ticket_details_cst
2021-08-05 17:19:32.024923 (Thread-1): Writing injected SQL for node "model.customer_history.order_ticket_details_cst"
2021-08-05 17:19:32.025299 (Thread-1): finished collecting timing info
2021-08-05 17:19:32.049458 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:19:32.049626 (Thread-1): On model.customer_history.order_ticket_details_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_ticket_details_cst"} */
drop table if exists "data_platform_prod"."data_science"."order_ticket_details_cst__dbt_tmp" cascade
2021-08-05 17:19:32.101820 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2021-08-05 17:19:32.104389 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:19:32.104492 (Thread-1): On model.customer_history.order_ticket_details_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_ticket_details_cst"} */
drop table if exists "data_platform_prod"."data_science"."order_ticket_details_cst__dbt_backup" cascade
2021-08-05 17:19:32.157128 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2021-08-05 17:19:32.158658 (Thread-1): Writing runtime SQL for node "model.customer_history.order_ticket_details_cst"
2021-08-05 17:19:32.159079 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:19:32.159170 (Thread-1): On model.customer_history.order_ticket_details_cst: BEGIN
2021-08-05 17:19:32.213959 (Thread-1): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:19:32.214115 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:19:32.214196 (Thread-1): On model.customer_history.order_ticket_details_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_ticket_details_cst"} */


  create  table "data_platform_prod"."data_science"."order_ticket_details_cst__dbt_tmp"
  as (
    -- calculate distance between customer location vs event location -- 

with orders as (
    SELECT * FROM "data_platform_prod"."data_science"."order_flash_events_cst"       
),
customers as (
    SELECT * FROM "data_platform_prod"."data_science"."stg_customers"
),
zipcodes as (
    select zipcode, longitude, latitude from public.us_zipcodes
    where primary_record='P'
),
-- customers_zip as (
--     Select
--         customers.*,
--         CAST(longitude AS DOUBLE PRECISION) as customer_long,
--         CAST(latitude AS DOUBLE PRECISION) as customer_lat
--     FROM customers LEFT JOIN zipcodes ON customers.zip=zipcodes.zipcode
-- ),
-- orders_zip as (
--     Select
--         orders.*,
--         CAST(longitude AS DOUBLE PRECISION) as venue_long,
--         CAST(latitude AS DOUBLE PRECISION) as venue_lat
--     FROM orders LEFT JOIN zipcodes ON orders.venue_zip=zipcodes.zipcode
-- ),
final as (
    SELECT
        customer_unique_id,
        axs_email_hash,
        order_ticket_unique_id,
        ROW_NUMBER() over (PARTITION BY order_ticket_unique_id ORDER BY 
        order_ticket_unique_id) AS order_ticket_identifier, -- to remove duplicate order_ticket_unique_id
        order_unique_id,
        amount_gross,
        channel,
        sale_datetime,
        pricing_mode_id,
        -- price_code_type,
        is_season_ticket,
        transfer_action_id,
        event_unique_id,
        ticket_id,
        ticket_state,
        days_sold_after_onsale,
        days_sold_before_event,
        venue_unique_id,
        venue_type,
        major_category_name,
        is_canceled,
        round(ST_DistanceSphere(ST_Point(CAST(c_zip.longitude AS DOUBLE PRECISION), CAST(c_zip.latitude AS DOUBLE PRECISION)), 
        ST_Point(CAST(v_zip.longitude AS DOUBLE PRECISION), CAST(v_zip.latitude AS DOUBLE PRECISION))) / 1000, 0) AS order_distance_in_km,
        order_distance_in_km / 1.6 AS order_distance_in_miles
    from customers
    INNER join orders using (customer_unique_id)
    LEFT JOIN zipcodes c_zip ON customers.zip=c_zip.zipcode
    LEFT JOIN zipcodes v_zip ON orders.venue_zip=v_zip.zipcode
)

SELECT * FROM final
  );
2021-08-05 17:29:26.150521 (Thread-1): SQL status: SELECT in 593.94 seconds
2021-08-05 17:29:26.154960 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:29:26.155072 (Thread-1): On model.customer_history.order_ticket_details_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_ticket_details_cst"} */
alter table "data_platform_prod"."data_science"."order_ticket_details_cst" rename to "order_ticket_details_cst__dbt_backup"
2021-08-05 17:29:26.209283 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2021-08-05 17:29:26.211800 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:29:26.211914 (Thread-1): On model.customer_history.order_ticket_details_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_ticket_details_cst"} */
alter table "data_platform_prod"."data_science"."order_ticket_details_cst__dbt_tmp" rename to "order_ticket_details_cst"
2021-08-05 17:29:26.280484 (Thread-1): SQL status: ALTER TABLE in 0.07 seconds
2021-08-05 17:29:26.281672 (Thread-1): On model.customer_history.order_ticket_details_cst: COMMIT
2021-08-05 17:29:26.281825 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:29:26.281942 (Thread-1): On model.customer_history.order_ticket_details_cst: COMMIT
2021-08-05 17:29:28.635156 (Thread-1): SQL status: COMMIT in 2.35 seconds
2021-08-05 17:29:28.637130 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_cst".
2021-08-05 17:29:28.637285 (Thread-1): On model.customer_history.order_ticket_details_cst: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_ticket_details_cst"} */
drop table if exists "data_platform_prod"."data_science"."order_ticket_details_cst__dbt_backup" cascade
2021-08-05 17:29:28.880468 (Thread-1): SQL status: DROP TABLE in 0.24 seconds
2021-08-05 17:29:28.882848 (Thread-1): finished collecting timing info
2021-08-05 17:29:28.883440 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '514e5a93-640c-4b19-b52b-9dd92a0bdfe3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090c9210>]}
2021-08-05 17:29:28.883640 (Thread-1): 10:29:28 | 12 of 17 OK created table model data_science.order_ticket_details_cst [SELECT in 596.87s]
2021-08-05 17:29:28.883756 (Thread-1): Finished running node model.customer_history.order_ticket_details_cst
2021-08-05 17:29:28.883873 (Thread-1): Began running node model.customer_history.order_ticket_details_est
2021-08-05 17:29:28.884024 (Thread-1): 10:29:28 | 13 of 17 START table model data_science.order_ticket_details_est..... [RUN]
2021-08-05 17:29:28.884365 (Thread-1): Acquiring new postgres connection "model.customer_history.order_ticket_details_est".
2021-08-05 17:29:28.884461 (Thread-1): Re-using an available connection from the pool (formerly model.customer_history.order_ticket_details_cst).
2021-08-05 17:29:28.884576 (Thread-1): Compiling model.customer_history.order_ticket_details_est
2021-08-05 17:29:28.892142 (Thread-1): Writing injected SQL for node "model.customer_history.order_ticket_details_est"
2021-08-05 17:29:28.892516 (Thread-1): finished collecting timing info
2021-08-05 17:29:28.898545 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_est".
2021-08-05 17:29:28.898657 (Thread-1): On model.customer_history.order_ticket_details_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_ticket_details_est"} */
drop table if exists "data_platform_prod"."data_science"."order_ticket_details_est__dbt_tmp" cascade
2021-08-05 17:29:28.949681 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2021-08-05 17:29:28.952261 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_est".
2021-08-05 17:29:28.952384 (Thread-1): On model.customer_history.order_ticket_details_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_ticket_details_est"} */
drop table if exists "data_platform_prod"."data_science"."order_ticket_details_est__dbt_backup" cascade
2021-08-05 17:29:29.006704 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2021-08-05 17:29:29.008650 (Thread-1): Writing runtime SQL for node "model.customer_history.order_ticket_details_est"
2021-08-05 17:29:29.009160 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_est".
2021-08-05 17:29:29.009333 (Thread-1): On model.customer_history.order_ticket_details_est: BEGIN
2021-08-05 17:29:29.056565 (Thread-1): SQL status: BEGIN in 0.05 seconds
2021-08-05 17:29:29.056749 (Thread-1): Using postgres connection "model.customer_history.order_ticket_details_est".
2021-08-05 17:29:29.056848 (Thread-1): On model.customer_history.order_ticket_details_est: /* {"app": "dbt", "dbt_version": "0.16.1", "profile_name": "axs", "target_name": "dev", "node_id": "model.customer_history.order_ticket_details_est"} */


  create  table "data_platform_prod"."data_science"."order_ticket_details_est__dbt_tmp"
  as (
    -- calculate distance between customer location vs event location -- 

with orders as (
    SELECT * FROM "data_platform_prod"."data_science"."order_flash_events_est"       
),
customers as (
    SELECT * FROM "data_platform_prod"."data_science"."stg_customers"
),
zipcodes as (
    select zipcode, longitude, latitude from public.us_zipcodes
    where primary_record='P'
),
-- customers_zip as (
--     Select
--         customers.*,
--         CAST(longitude AS DOUBLE PRECISION) as customer_long,
--         CAST(latitude AS DOUBLE PRECISION) as customer_lat
--     FROM customers LEFT JOIN zipcodes ON customers.zip=zipcodes.zipcode
-- ),
-- orders_zip as (
--     Select
--         orders.*,
--         CAST(longitude AS DOUBLE PRECISION) as venue_long,
--         CAST(latitude AS DOUBLE PRECISION) as venue_lat
--     FROM orders LEFT JOIN zipcodes ON orders.venue_zip=zipcodes.zipcode
-- ),
final as (
    SELECT
        customer_unique_id,
        axs_email_hash,
        order_ticket_unique_id,
        ROW_NUMBER() over (PARTITION BY order_ticket_unique_id ORDER BY 
        order_ticket_unique_id) AS order_ticket_identifier, -- to remove duplicate order_ticket_unique_id
        order_unique_id,
        amount_gross,
        channel,
        sale_datetime,
        pricing_mode_id,
        -- price_code_type,
        is_season_ticket,
        transfer_action_id,
        event_unique_id,
        ticket_id,
        ticket_state,
        days_sold_after_onsale,
        days_sold_before_event,
        venue_unique_id,
        venue_type,
        major_category_name,
        is_canceled,
        round(ST_DistanceSphere(ST_Point(CAST(c_zip.longitude AS DOUBLE PRECISION), CAST(c_zip.latitude AS DOUBLE PRECISION)), 
        ST_Point(CAST(v_zip.longitude AS DOUBLE PRECISION), CAST(v_zip.latitude AS DOUBLE PRECISION))) / 1000, 0) AS order_distance_in_km,
        order_distance_in_km / 1.6 AS order_distance_in_miles
    from customers
    INNER join orders using (customer_unique_id)
    LEFT JOIN zipcodes c_zip ON customers.zip=c_zip.zipcode
    LEFT JOIN zipcodes v_zip ON orders.venue_zip=v_zip.zipcode
)

SELECT * FROM final
  );
